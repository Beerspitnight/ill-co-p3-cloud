# Ill-Co-P3.2: Visual Design Tagging Tool

## ğŸ§  Project Summary
This project builds a dataset to fine-tune an AI model on visual design principles. Users tag image-text examples via a Streamlit interface. The project integrates Firebase for authentication, image hosting, and tagging data storage.

## ğŸš€ Features
- Firebase login (email/password) with email verification
- Tagging UI for image-text pairs
- Auto-save tags to Firebase Realtime DB
- Downloadable exports (JSON, CSV)
- GPT-assisted label suggestions (optional)
- Sidebar with hoverable reference examples

## ğŸ“ Project Structure
```
ill-co-p3.2/
â”œâ”€â”€ learning_app/
â”‚   â”œâ”€â”€ data/                  # HTML and image inputs
â”‚   â”œâ”€â”€ output/                # Enriched metadata, tag results
â”‚   â”‚   â”œâ”€â”€ books_enriched/    
â”‚   â”‚   â”œâ”€â”€ pairs/             # image_urls.json, combined_pairs.json, etc.
â”‚   â”œâ”€â”€ scripts/               # All utility scripts
â”‚   â”œâ”€â”€ styles/                # CSS styling
â”‚   â”œâ”€â”€ utils/                 # GPT prompts, Firebase helpers
â”œâ”€â”€ secrets/                  # âœ… Only location for secrets
â”‚   â”œâ”€â”€ secrets.toml           # All credentials
â”‚   â”œâ”€â”€ ill-co-p3-learns-firebase-adminsdk.json
â”œâ”€â”€ dataset_interface2.py     # Streamlit UI app
â”œâ”€â”€ README.md                 # You're reading it
```

## ğŸ” Credentials
All secrets are loaded from:
```
/Users/bmcmanus/Documents/my_docs/portfolio/secrets/
```
Do **not** use `.env` or duplicate secrets in `.streamlit/`.

Python scripts load credentials like this:
```python
import toml
SECRETS_PATH = "/Users/bmcmanus/Documents/my_docs/portfolio/secrets/secrets.toml"
secrets = toml.load(SECRETS_PATH)

firebase_creds = secrets["FIREBASE"]
openai_key = secrets["OPENAI"]["OPENAI_API_KEY"]
google_books_key = secrets["GOOGLE"]["GOOGLE_BOOKS_API_KEY"]
```

## ğŸ› ï¸ Running the App
1. Activate your virtual environment
2. Run the tagging app:
```bash
streamlit run dataset_interface2.py
```

## âœ… Script Status Overview
See `âœ… Summary of All Scripts & Their Roles.docx` for details. Highlights:
- `extract_images.py`, `match_text_image.py` â€” âœ… Locked
- `export_firebase_tags.py` â€” âœ… Working
- `bulk_enrich_books.py` â€” ğŸ”² To be implemented
- `dataset_interface2.py` â€” âœ… Ready for tagging

## ğŸ—ƒï¸ Outputs
- Tagged results:
  - `output/pairs/tagged_results.json`
  - `output/pairs/tagged_results.csv`
- GPT-labeled samples:
  - `output/pairs/gpt_images_labeled_sample/gpt_images_labeled_sample.json`

## ğŸ§¾ Version Control
- Locked scripts are marked with `# ğŸ”’ LOCKED - DO NOT MODIFY`
- Backups live in `output/pairs/backups/`
- Exports are timestamped to avoid overwriting

## ğŸ§° Tools & Utilities

### ğŸ” LibraryCloud API Test Interface

A simple local HTML interface to test your book search endpoints using Google Books and OpenLibrary.

- File: `learning_app/templates/api_s_index.html`
- Use: Load in a browser or wrap in a Flask route
- Features:
  - Search Google Books API
  - Search OpenLibrary API
  - View saved result list

To view locally, open in browser or visit `/dev/api` (if Flask route enabled).
---
**Pathfinder Project** | Built for visual design training | Powered by GPT + Firebase